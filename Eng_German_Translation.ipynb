{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng-German_Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CrMOeSKeHyS",
        "outputId": "e0e34d3f-3b01-4f65-8940-0ba7c558e586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqjkrAJTek21",
        "outputId": "41443e09-a949-4aea-db33-d0d502db3c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = \"/content/drive/My Drive/datasets/deu.txt\""
      ],
      "metadata": {
        "id": "osu1UGMxnmm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "lines = io.open(path_to_file, encoding='UTF-8').read().strip().split('\\n')\n"
      ],
      "metadata": {
        "id": "vYMSHKTSn00C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-DErCH1rqWH",
        "outputId": "9744cf05-d2b3-4c28-d0e5-1e3dda4d6c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "248311"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10000"
      ],
      "metadata": {
        "id": "2EzfRmLjqwOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = []\n",
        "target_texts = []"
      ],
      "metadata": {
        "id": "c4IgbGkBrfYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in lines[:min(num_samples, len(lines)-1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "gDDSfovfqpTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go2Wfcj0rnbH",
        "outputId": "e6df57c8-0572-4cb6-83fa-e028d14cb40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#specify a start and end for each sentence\n",
        "\n",
        "for i in range(len(input_texts)):\n",
        "  input_texts[i] = '<start> '+input_texts[i]+' <end>'\n",
        "\n",
        "for i in range(len(target_texts)):\n",
        "  target_texts[i] = '<start> '+target_texts[i]+' <end>'"
      ],
      "metadata": {
        "id": "qsLDs8c9Zl3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorise the words based on tokenisation\n",
        "#internal vocabulary created based on which word vectors are formed\n",
        "\n",
        "def tokenize(texts):\n",
        "\n",
        "  vocab = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "\n",
        "  #form the internal vocabulary\n",
        "  vocab.fit_on_texts(texts)\n",
        "\n",
        "  #form vectors, internal vocab to numbers\n",
        "  word_vec = vocab.texts_to_sequences(texts)\n",
        "\n",
        "  #since the input statements are of different length\n",
        "  #we will do padding, to make the vectors of equal length\n",
        "  word_vec = tf.keras.preprocessing.sequence.pad_sequences(word_vec, padding='post')\n",
        "\n",
        "  return word_vec, vocab\n"
      ],
      "metadata": {
        "id": "40NowZRDruHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_vec, inp_vocab = tokenize(input_texts)\n",
        "targ_vec, targ_vocab = tokenize(target_texts)"
      ],
      "metadata": {
        "id": "gHAoP13nosGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_vec[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF3kctmhvqv3",
        "outputId": "5ef07f7a-e581-497a-b223-7c312ce8bfcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, 56,  2,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inp_vocab.index_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAArO58co-7Z",
        "outputId": "a04b55ae-632c-4a00-da5c-870849ea8538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: '<start>', 2: '<end>', 3: 'i', 4: 'tom', 5: \"i'm\", 6: 'is', 7: 'a', 8: 'you', 9: 'it', 10: 'it.', 11: \"it's\", 12: 'was', 13: 'he', 14: 'tom.', 15: 'we', 16: 'me.', 17: 'do', 18: 'can', 19: \"don't\", 20: 'are', 21: 'to', 22: \"i'll\", 23: 'go', 24: 'get', 25: 'you.', 26: 'my', 27: \"you're\", 28: 'have', 29: 'the', 30: 'be', 31: 'she', 32: 'like', 33: 'come', 34: 'who', 35: \"we're\", 36: 'not', 37: \"tom's\", 38: 'up.', 39: 'keep', 40: 'this', 41: 'love', 42: 'they', 43: 'did', 44: 'that', 45: 'take', 46: 'am', 47: 'let', 48: 'here.', 49: 'need', 50: 'me', 51: \"that's\", 52: 'no', 53: 'how', 54: \"he's\", 55: \"let's\", 56: 'go.', 57: 'stop', 58: 'want', 59: 'home.', 60: 'that.', 61: 'saw', 62: 'him.', 63: 'this.', 64: 'got', 65: 'it?', 66: 'may', 67: 'us.', 68: 'now.', 69: 'has', 70: 'just', 71: 'in.', 72: \"they're\", 73: 'on', 74: \"can't\", 75: 'hate', 76: 'will', 77: 'you?', 78: \"we'll\", 79: 'try', 80: 'in', 81: 'look', 82: 'see', 83: 'please', 84: 'so', 85: 'know', 86: 'what', 87: 'too', 88: 'for', 89: 'your', 90: 'down.', 91: 'give', 92: 'on.', 93: 'eat', 94: 'out.', 95: 'there.', 96: 'away.', 97: \"i've\", 98: 'at', 99: 'very', 100: 'were', 101: 'them.', 102: 'feel', 103: 'one.', 104: 'had', 105: 'one', 106: \"wasn't\", 107: 'ok.', 108: 'help', 109: 'busy.', 110: 'stay', 111: 'again.', 112: 'must', 113: 'ask', 114: 'away!', 115: 'an', 116: 'made', 117: 'found', 118: 'open', 119: 'wait', 120: 'come.', 121: 'car.', 122: 'leave', 123: \"who's\", 124: 'her.', 125: 'went', 126: 'all', 127: 'back.', 128: 'alone.', 129: 'nobody', 130: 'me?', 131: 'good.', 132: 'work.', 133: \"isn't\", 134: 'lost.', 135: 'hard.', 136: 'said', 137: 'right.', 138: 'cold.', 139: 'it!', 140: 'hold', 141: 'ready.', 142: 'walk.', 143: 'happy.', 144: 'with', 145: 'hot.', 146: 'win.', 147: 'fun.', 148: 'late.', 149: 'miss', 150: 'came', 151: 'use', 152: 'upset.', 153: 'mine.', 154: 'sad.', 155: 'fast.', 156: 'help.', 157: 'that?', 158: 'beat', 159: 'fine.', 160: 'sick.', 161: 'well.', 162: 'here', 163: 'wrong.', 164: 'hurt.', 165: 'wait.', 166: 'call', 167: 'bad.', 168: 'watch', 169: 'say', 170: \"won't\", 171: \"didn't\", 172: 'book.', 173: 'too.', 174: 'hurts.', 175: 'over.', 176: 'sing.', 177: 'read', 178: 'now', 179: 'door.', 180: 'try.', 181: 'know.', 182: 'swim.', 183: 'tell', 184: 'us', 185: 'start', 186: 'job.', 187: 'told', 188: 'lot.', 189: 'does', 190: 'money.', 191: 'old.', 192: 'back', 193: 'off.', 194: 'cry.', 195: 'lost', 196: 'drunk.', 197: 'of', 198: 'never', 199: 'dog.', 200: 'this?', 201: 'show', 202: 'up!', 203: 'sit', 204: 'bed.', 205: 'lying.', 206: 'tom?', 207: \"what's\", 208: 'ate', 209: 'quiet.', 210: 'him', 211: 'more.', 212: 'turn', 213: 'felt', 214: 'cool.', 215: 'mad.', 216: 'me!', 217: 'lost!', 218: 'trust', 219: 'knew', 220: 'angry.', 221: 'easy.', 222: 'put', 223: \"tom'll\", 224: 'mary', 225: 'won.', 226: 'hit', 227: 'die.', 228: 'bring', 229: 'check', 230: 'great.', 231: 'please.', 232: 'yourself.', 233: 'young.', 234: 'cut', 235: 'looks', 236: 'stay.', 237: 'new.', 238: 'find', 239: 'fix', 240: 'so.', 241: 'crazy.', 242: 'early.', 243: 'time.', 244: 'make', 245: 'french.', 246: 'kill', 247: 'stand', 248: 'eat.', 249: 'help?', 250: 'where', 251: 'here?', 252: 'naive.', 253: 'up', 254: 'run.', 255: 'buy', 256: 'go?', 257: 'bored.', 258: 'tired.', 259: 'loved', 260: \"it'll\", 261: 'way.', 262: 'needs', 263: 'rest.', 264: 'there', 265: 'see.', 266: 'hug', 267: 'left.', 268: 'shy.', 269: 'brave.', 270: 'tried.', 271: 'free.', 272: 'big.', 273: 'met', 274: 'talk.', 275: 'dying.', 276: \"she's\", 277: 'food.', 278: 'busy?', 279: 'loves', 280: 'and', 281: 'knows', 282: 'likes', 283: 'nice.', 284: 'fat.', 285: 'weak.', 286: 'tea.', 287: 'write', 288: 'cook.', 289: 'sorry.', 290: 'move', 291: 'by', 292: 'wine.', 293: 'drink', 294: 'ran', 295: 'hurry.', 296: 'there?', 297: 'stupid.', 298: 'nothing.', 299: 'hurt', 300: 'wants', 301: 'play', 302: 'reading.', 303: 'running.', 304: 'singing.', 305: 'begin.', 306: 'join', 307: 'wake', 308: 'still.', 309: 'catch', 310: 'by.', 311: 'rich.', 312: 'speak', 313: 'died.', 314: 'gave', 315: 'hope', 316: \"i'd\", 317: 'in?', 318: 'new?', 319: 'careful.', 320: 'boy.', 321: 'broke', 322: 'water.', 323: 'bus.', 324: 'all.', 325: 'why.', 326: 'beer.', 327: 'mary.', 328: 'lucky.', 329: 'over', 330: 'now?', 331: 'dumped', 332: 'today.', 333: 'coffee.', 334: 'fell.', 335: 'why', 336: 'quit.', 337: 'agree.', 338: 'shut', 339: 'man.', 340: 'smiled.', 341: 'sure.', 342: 'ugly.', 343: 'go!', 344: 'inside.', 345: 'head', 346: 'cheated.', 347: 'leave.', 348: 'fail.', 349: 'stop.', 350: 'awake.', 351: 'ok?', 352: 'listen', 353: 'step', 354: \"who'll\", 355: 'drive.', 356: 'come?', 357: 'off', 358: 'good', 359: 'hear', 360: 'talk', 361: 'bit', 362: 'fired.', 363: 'half.', 364: 'called', 365: 'map.', 366: 'fighting.', 367: 'applauded.', 368: 'looked', 369: 'close', 370: 'kind.', 371: 'out!', 372: 'came.', 373: 'lie', 374: 'low.', 375: 'lock', 376: 'mean.', 377: 'safe.', 378: 'thin.', 379: 'knew.', 380: 'touch', 381: 'lie.', 382: 'forget', 383: 'ill.', 384: 'laughed.', 385: 'no.', 386: 'calm.', 387: 'knows.', 388: 'life.', 389: 'think', 390: 'rude.', 391: 'better.', 392: 'coming.', 393: 'strong.', 394: 'these.', 395: 'called.', 396: \"you've\", 397: 'hurt?', 398: 'swim?', 399: 'fish.', 400: 'eggs.', 401: 'work', 402: 'joke.', 403: 'send', 404: 'crying.', 405: 'caution.', 406: 'school.', 407: 'hand.', 408: 'seems', 409: 'hugged', 410: 'cat.', 411: 'only', 412: 'should', 413: 'it,', 414: 'some', 415: 'unfair.', 416: \"one's\", 417: 'everybody', 418: 'ran.', 419: 'lied.', 420: 'sang.', 421: 'drop', 422: 'hang', 423: 'wet.', 424: 'down!', 425: 'ahead.', 426: 'hurry', 427: 'pay.', 428: 'save', 429: 'lost?', 430: 'dogs', 431: 'spy.', 432: 'blind.', 433: 'yours.', 434: 'ignore', 435: 'gone.', 436: 'ours.', 437: 'nice', 438: 'right?', 439: 'men', 440: 'cruel.', 441: 'smart.', 442: 'drank', 443: 'sat', 444: 'shot', 445: 'survived.', 446: 'bet.', 447: 'read.', 448: 'disagreed.', 449: 'dizzy.', 450: 'kids.', 451: 'eyes.', 452: 'dancing.', 453: 'yours?', 454: 'life', 455: 'shall', 456: 'once.', 457: 'forward.', 458: 'drink.', 459: 'could', 460: 'enjoy', 461: 'joking.', 462: 'pay', 463: 'out', 464: 'black.', 465: 'working.', 466: 'closely.', 467: \"they'll\", 468: 'expert.', 469: 'us?', 470: 'boston.', 471: 'hurry!', 472: 'relax.', 473: 'care.', 474: 'fair.', 475: 'cried.', 476: 'tall.', 477: 'soon.', 478: \"here's\", 479: 'changed.', 480: 'relaxed.', 481: 'took', 482: 'woke', 483: 'broke.', 484: 'going.', 485: 'tough.', 486: 'tv.', 487: 'dark.', 488: 'true.', 489: 'warm.', 490: 'moved.', 491: 'failed.', 492: 'dying?', 493: 'patient.', 494: 'sing?', 495: 'look.', 496: 'god', 497: 'built', 498: 'rice.', 499: 'afraid.', 500: 'biased.', 501: 'eating.', 502: 'hiding.', 503: 'losing.', 504: 'trying.', 505: 'love?', 506: \"tom's.\", 507: 'pick', 508: 'sec.', 509: 'sick?', 510: 'home?', 511: 'say.', 512: 'started.', 513: 'seat.', 514: 'asleep.', 515: 'dad.', 516: 'apologize.', 517: 'bought', 518: 'liked', 519: 'duty.', 520: 'talking.', 521: 'thirsty.', 522: 'break.', 523: 'simple.', 524: 'sent', 525: 'lose.', 526: 'funny.', 527: 'quickly.', 528: 'something.', 529: 'happy', 530: 'still', 531: 'short.', 532: 'hated', 533: 'do?', 534: 'key.', 535: 'tomorrow.', 536: 'downstairs.', 537: 'smells', 538: 'hot', 539: 'student.', 540: 'going', 541: 'moment.', 542: \"doesn't\", 543: 'won!', 544: 'on!', 545: 'kiss', 546: 'pull', 547: 'you!', 548: 'ate.', 549: 'wash', 550: 'drive', 551: 'grab', 552: 'helped.', 553: 'dj.', 554: 'bald.', 555: 'okay.', 556: 'warn', 557: 'he?', 558: 'fly.', 559: 'excuse', 560: 'lazy.', 561: 'slipped.', 562: 'stopped.', 563: 'live.', 564: 'obey.', 565: 'first.', 566: 'obese.', 567: 'hot?', 568: 'agreed.', 569: \"we've\", 570: 'start.', 571: 'around.', 572: 'serious.', 573: 'move.', 574: 'slowly.', 575: 'moving.', 576: 'work?', 577: 'canceled.', 578: 'promised.', 579: 'hungry.', 580: 'lonely.', 581: 'done?', 582: 'alive.', 583: 'clean.', 584: 'quiet', 585: 'replace', 586: 'smell', 587: 'sharp.', 588: 'break', 589: 'closer.', 590: 'count', 591: 'guess', 592: 'helps', 593: 'relented.', 594: 'age.', 595: 'here,', 596: 'adore', 597: 'milk.', 598: 'math.', 599: 'live', 600: 'often', 601: 'manage.', 602: 'nervous.', 603: 'outside.', 604: 'study.', 605: 'cute.', 606: 'last.', 607: 'vain.', 608: 'boil', 609: 'gun.', 610: 'up,', 611: 'another.', 612: 'admire', 613: 'ashamed.', 614: 'music.', 615: 'sleep.', 616: 'fool.', 617: 'stoned.', 618: 'doctor.', 619: 'busy', 620: 'doing', 621: 'dead.', 622: 'safe', 623: 'studying.', 624: 'smiling.', 625: 'guess.', 626: 'these', 627: 'quit', 628: 'down', 629: 'silly.', 630: 'shot.', 631: 'them', 632: 'bit?', 633: 'bored?', 634: 'left', 635: 'enough.', 636: 'horse.', 637: 'seen', 638: \"nobody's\", 639: 'change.', 640: 'adores', 641: \"aren't\", 642: 'joking!', 643: 'yoga?', 644: 'word.', 645: 'smile.', 646: 'paid.', 647: 'way!', 648: 'hi,', 649: 'spoke.', 650: 'prayed.', 651: 'shaved.', 652: 'stayed.', 653: 'deaf.', 654: 'full.', 655: 'tidy.', 656: 'works.', 657: 'birds', 658: 'follow', 659: 'escaped.', 660: 'fainted.', 661: 'mean', 662: 'call.', 663: 'stuck.', 664: 'course!', 665: 'seriously?', 666: 'sign', 667: 'that!', 668: 'thank', 669: 'stood.', 670: 'forgive', 671: 'poor.', 672: 'is!', 673: \"how's\", 674: 'not.', 675: 'panicked.', 676: 'remember.', 677: 'resigned.', 678: 'ok', 679: 'chubby.', 680: 'famous.', 681: 'greedy.', 682: 'single.', 683: 'out?', 684: 'ours?', 685: 'close.', 686: 'white.', 687: 'aside.', 688: 'study', 689: 'cheat.', 690: 'time', 691: 'harder.', 692: 'next?', 693: 'decide.', 694: 'later.', 695: 'laugh.', 696: 'home', 697: 'liar.', 698: 'wasted.', 699: 'asked', 700: 'fruit.', 701: 'rain.', 702: 'hired', 703: 'overslept.', 704: 'saved', 705: 'naked.', 706: 'scream.', 707: 'dieting.', 708: 'humming.', 709: 'love.', 710: 'injured.', 711: 'useless.', 712: 'winning.', 713: 'legal?', 714: 'boring.', 715: 'secret.', 716: 'urgent.', 717: 'card.', 718: 'enter.', 719: 'goodbye.', 720: 'wise.', 721: 'gets', 722: 'evil.', 723: 'pale.', 724: 'weird.', 725: 'vote', 726: 'walk', 727: 'cook?', 728: 'first?', 729: 'egg.', 730: 'upstairs.', 731: 'poet.', 732: 'runs', 733: 'hey,', 734: 'kid.', 735: 'proof.', 736: 'cab.', 737: 'sleepy.', 738: 'alive?', 739: 'happy?', 740: 'true?', 741: 'works', 742: 'happen.', 743: 'correct.', 744: 'turn.', 745: 'our', 746: 'driving.', 747: 'walking.', 748: 'writing.', 749: 'dream.', 750: 'witty.', 751: 'guilty.', 752: 'paying.', 753: 'joking?', 754: 'teacher.', 755: 'mind', 756: 'kite.', 757: 'lay', 758: 'his', 759: 'about', 760: 'plan.', 761: 'wife.', 762: 'son.', 763: 'quite', 764: 'wanted', 765: 'hungry?', 766: 'suit', 767: 'girls', 768: 'kept', 769: 'hide', 770: 'friends.', 771: 'truck.', 772: 'teach', 773: 'stop!', 774: 'hid.', 775: 'sorry?', 776: 'spit.', 777: 'wept.', 778: 'really?', 779: 'thanks.', 780: 'push', 781: 'brief.', 782: 'humor', 783: 'moaned.', 784: 'rested.', 785: 'waited.', 786: 'next.', 787: 'red.', 788: 'answer', 789: 'calm', 790: 'win?', 791: 'ski.', 792: 'fear', 793: 'hung', 794: 'picky.', 795: 'bad?', 796: 'burned.', 797: 'worked.', 798: 'jump', 799: 'be.', 800: 'tight.', 801: 'began.', 802: 'cares.', 803: 'slept.', 804: 'voted.', 805: 'walked.', 806: 'stink.', 807: 'wrong?', 808: 'stay?', 809: 'quick!', 810: 'faster.', 811: 'here!', 812: 'is.', 813: 'yes.', 814: 'shoot.', 815: 'hero.', 816: 'scared.', 817: 'thirty.', 818: 'tall?', 819: 'good?', 820: 'safe?', 821: 'awful.', 822: 'kidding?', 823: 'problem.', 824: 'oh,', 825: 'run', 826: 'nap.', 827: \"that'll\", 828: 'do.', 829: \"this'll\", 830: 'obeyed.', 831: 'fit?', 832: 'mad?', 833: 'creative.', 834: 'punctual.', 835: 'ruthless.', 836: 'breathe', 837: 'hat.', 838: 'begin?', 839: 'see?', 840: 'try?', 841: 'aboard.', 842: 'cook', 843: 'as', 844: 'fight.', 845: 'worry.', 846: 'hello', 847: 'are.', 848: 'twin.', 849: 'blame', 850: 'skate.', 851: 'cash.', 852: 'hesitated.', 853: 'hired.', 854: 'curious.', 855: 'leaving.', 856: 'married.', 857: 'stunned.', 858: 'well?', 859: 'gone?', 860: 'happened.', 861: 'fake.', 862: 'dance.', 863: 'fist.', 864: 'list.', 865: 'many', 866: 'smoke?', 867: 'memorize', 868: 'ok,', 869: 'release', 870: 'remember', 871: 'blushed.', 872: 'stick', 873: 'bath.', 874: 'hers.', 875: 'loud.', 876: 'paid', 877: 'watched.', 878: 'tipsy.', 879: 'tom,', 880: 'cheated?', 881: 'tired?', 882: 'anything', 883: 'alone?', 884: 'walk?', 885: 'anyway.', 886: 'best.', 887: 'yet.', 888: 'hand', 889: 'avoids', 890: 'hates', 891: 'almost', 892: 'always', 893: 'mind.', 894: 'plans.', 895: 'helped', 896: 'kissed', 897: 'tried', 898: 'watched', 899: 'sue', 900: 'canadian.', 901: 'diabetic.', 902: 'free', 903: 'freezing.', 904: 'shooting.', 905: 'awake?', 906: 'crazy?', 907: 'scary.', 908: 'perfect.', 909: 'focused.', 910: 'looking.', 911: 'learn', 912: 'quietly.', 913: 'eyes', 914: 'feet', 915: 'whining.', 916: 'shame', 917: 'pretty.', 918: 'someone', 919: 'sweet', 920: 'thanks', 921: 'grumbled.', 922: 'small.', 923: 'sweet.', 924: 'might', 925: 'polite.', 926: 'start?', 927: 'coming?', 928: 'scare', 929: \"you'll\", 930: 'grown.', 931: 'add', 932: 'angry?', 933: 'why?', 934: 'go,', 935: 'too?', 936: 'clean', 937: 'rush', 938: 'everyone', 939: 'day.', 940: 'fly', 941: 'boss.', 942: 'skating.', 943: 'tries', 944: 'already', 945: 'believe', 946: 'trusted', 947: 'worried.', 948: 'artist.', 949: 'uninsured.', 950: 'lonely?', 951: 'been', 952: 'minute.', 953: 'dog', 954: 'lungs', 955: 'gate.', 956: 'red', 957: 'roll', 958: 'dice.', 959: 'livid.', 960: 'skinny.', 961: 'unkind.', 962: 'wicked.', 963: 'rushed', 964: 'arrived.', 965: 'happened?', 966: 'seem', 967: 'more', 968: 'two', 969: 'one?', 970: 'everything.', 971: 'walked', 972: 'believed', 973: 'followed', 974: 'prisoner.', 975: 'lend', 976: 'doors.', 977: 'shoot!', 978: 'listen.', 979: 'burn', 980: 'goodbye!', 981: 'runs.', 982: 'drove.', 983: 'froze.', 984: 'swore.', 985: 'waved.', 986: 'long.', 987: 'fat?', 988: 'cursed.', 989: 'paused.', 990: 'winked.', 991: 'yawned.', 992: 'his.', 993: 'taste', 994: 'terrific!', 995: 'lies.', 996: 'swam.', 997: 'some.', 998: 'i?', 999: 'quit?', 1000: 'dead?', 1001: 'late?', 1002: 'seated.', 1003: 'bless', 1004: 'east.', 1005: 'am.', 1006: 'fire.', 1007: 'approve.', 1008: 'coughed.', 1009: 'frowned.', 1010: 'giggled.', 1011: 'promise.', 1012: 'retired.', 1013: 'shouted.', 1014: 'sober.', 1015: '7:45.', 1016: 'try!', 1017: 'loosen', 1018: 'repeat', 1019: 'seize', 1020: 'him!', 1021: 'walks.', 1022: 'what?', 1023: 'knelt.', 1024: 'forgot.', 1025: 'talked.', 1026: 'done.', 1027: 'up?', 1028: 'wonderful!', 1029: 'aim', 1030: 'higher.', 1031: 'fired?', 1032: 'along.', 1033: 'cry?', 1034: 'yell.', 1035: 'examine', 1036: 'fire', 1037: 'warm', 1038: 'night.', 1039: 'hello,', 1040: 'clever!', 1041: 'human.', 1042: 'meat.', 1043: 'envy', 1044: 'fixed', 1045: 'heard', 1046: 'listened.', 1047: 'ice.', 1048: 'threw', 1049: 'one!', 1050: 'whistled.', 1051: 'stand.', 1052: 'girl.', 1053: 'monk.', 1054: 'big?', 1055: 'free?', 1056: 'nice?', 1057: 'happens.', 1058: 'cd.', 1059: 'notes.', 1060: 'town.', 1061: 'once', 1062: 'cheese.', 1063: 'cover!', 1064: 'cheats.', 1065: 'odd.', 1066: 'war', 1067: 'owe', 1068: 'stupid?', 1069: 'discreet.', 1070: 'merciful.', 1071: 'prepared.', 1072: 'specific.', 1073: 'thorough.', 1074: 'vigilant.', 1075: 'stop?', 1076: 'comfort', 1077: 'contact', 1078: 'die?', 1079: 'bowl?', 1080: 'stare.', 1081: 'finish', 1082: 'flip', 1083: 'coin.', 1084: 'board.', 1085: 'chuckled.', 1086: 'hated.', 1087: 'squinted.', 1088: 'stood', 1089: 'catch!', 1090: 'dozing.', 1091: 'deny', 1092: 'dozed', 1093: 'bread.', 1094: 'exercised.', 1095: 'blue.', 1096: 'cats.', 1097: 'dogs.', 1098: 'cake.', 1099: 'snow.', 1100: 'face.', 1101: 'whispered.', 1102: 'attend.', 1103: 'nurse.', 1104: 'fasting.', 1105: 'healthy.', 1106: 'pain.', 1107: 'staying.', 1108: 'unhappy.', 1109: 'unusual.', 1110: 'wounded.', 1111: 'sure?', 1112: \"tom's?\", 1113: 'monday.', 1114: 'pity.', 1115: 'broken.', 1116: 'check.', 1117: 'start!', 1118: 'lunch', 1119: 'record', 1120: 'return', 1121: 'surprise', 1122: 'action.', 1123: 'nuts.', 1124: 'slow.', 1125: 'refused.', 1126: 'sweated.', 1127: 'pushy.', 1128: 'armed.', 1129: 'nuts!', 1130: 'correct?', 1131: 'anybody', 1132: 'ready?', 1133: 'objective.', 1134: 'read?', 1135: 'in,', 1136: 'know?', 1137: 'vote?', 1138: 'teach?', 1139: 'best!', 1140: 'forget.', 1141: 'rifle.', 1142: 'denied', 1143: 'cranky.', 1144: 'driven.', 1145: 'succeeded.', 1146: 'adored', 1147: 'baffled.', 1148: 'apples.', 1149: 'myself.', 1150: 'deserve', 1151: 'doubts.', 1152: 'those.', 1153: 'pen.', 1154: 'books.', 1155: 'candy.', 1156: 'pizza.', 1157: 'missed', 1158: 'hug.', 1159: 'prefer', 1160: 'jam.', 1161: 'sell', 1162: 'sympathize.', 1163: 'thought', 1164: 'learn.', 1165: 'wrote', 1166: 'explain.', 1167: 'lawyer.', 1168: 'addicted.', 1169: 'ears.', 1170: 'divorced.', 1171: 'saint.', 1172: 'blame.', 1173: 'using', 1174: 'drunk?', 1175: 'enough?', 1176: 'mine?', 1177: 'cool?', 1178: 'curse.', 1179: 'bedtime.', 1180: 'raining.', 1181: 'snowing.', 1182: 'strange.', 1183: 'think.', 1184: 'jaw', 1185: 'set', 1186: 'pushing.', 1187: 'smoking.', 1188: 'yelling!', 1189: 'coat.', 1190: 'things', 1191: 'gold.', 1192: 'grimaced.', 1193: 'moody.', 1194: 'objected.', 1195: 'showered.', 1196: 'vanished.', 1197: 'insane.', 1198: 'lunch.', 1199: 'hope.', 1200: 'welcome', 1201: 'absent?', 1202: 'amuse', 1203: 'car', 1204: 'air', 1205: 'futon.', 1206: 'any', 1207: 'kids!', 1208: 'security.', 1209: 'stand?', 1210: 'cats', 1211: 'dream?', 1212: 'fish', 1213: 'follow?', 1214: 'lose', 1215: 'even', 1216: 'eaten?', 1217: 'maid.', 1218: 'braces.', 1219: 'english.', 1220: 'lied', 1221: 'talks', 1222: 'grouch.', 1223: 'after', 1224: 'or', 1225: 'rope.', 1226: 'look?', 1227: 'old', 1228: 'accelerated.', 1229: 'japanese.', 1230: 'smoke.', 1231: 'cried', 1232: 'hair.', 1233: 'fell', 1234: 'winter.', 1235: 'bike.', 1236: 'led', 1237: 'movies.', 1238: 'onions.', 1239: 'sports.', 1240: 'mom.', 1241: 'own', 1242: 'really', 1243: 'mouse.', 1244: 'allow', 1245: 'prove', 1246: 'man', 1247: 'afraid', 1248: 'exhausted.', 1249: 'important.', 1250: 'famous?', 1251: 'damaged?', 1252: 'working?', 1253: 'worse.', 1254: 'cold', 1255: 'fault.', 1256: 'climbing.', 1257: 'mine', 1258: 'foot', 1259: 'suits', 1260: 'clapping.', 1261: 'swearing.', 1262: 'number.', 1263: \"that'd\", 1264: 'confessed.', 1265: 'graduated.', 1266: 'abroad.', 1267: 'family.', 1268: 'second.', 1269: 'survive.', 1270: 'lawyers.', 1271: 'drunk!', 1272: \"you'd\", 1273: 'modest.', 1274: 'deeply.', 1275: 'ball.', 1276: 'engine.', 1277: '30?', 1278: 'recycle?', 1279: 'judge', 1280: 'ride.', 1281: 'new', 1282: 'arrived?', 1283: 'became', 1284: 'beard.', 1285: 'worked', 1286: 'everyone!', 1287: 'made?', 1288: 'flies!', 1289: 'dad?', 1290: 'betrayed', 1291: 'hailed', 1292: 'idea.', 1293: 'fishing.', 1294: 'phone', 1295: 'guy.', 1296: 'salesman.', 1297: 'optimistic.', 1298: 'taking', 1299: 'fit.', 1300: 'good!', 1301: 'sale.', 1302: 'brand', 1303: 'pointless.', 1304: 'hour.', 1305: 'tag.', 1306: 'this!', 1307: 'listen,', 1308: 'ditched', 1309: 'hi.', 1310: 'wow!', 1311: 'fire!', 1312: 'help!', 1313: 'hello!', 1314: 'attack!', 1315: 'freeze!', 1316: 'hop', 1317: 'fled.', 1318: '19.', 1319: 'snore.', 1320: 'ate?', 1321: 'ran?', 1322: 'cool', 1323: 'cuff', 1324: 'tries.', 1325: 'cute!', 1326: 'rude!', 1327: 'jumped.', 1328: 'nodded.', 1329: 'refuse.', 1330: 'game.', 1331: 'dry.', 1332: 'for?', 1333: 'came?', 1334: 'died?', 1335: 'fell?', 1336: 'swam?', 1337: 'home!', 1338: 'eat?', 1339: 'ask.', 1340: 'fantastic!', 1341: 'goodnight.', 1342: 'clapped.', 1343: 'fussy.', 1344: 'needy.', 1345: 'ready!', 1346: 'snowed.', 1347: 'stinks.', 1348: '9:15.', 1349: 'open.', 1350: 'sand.', 1351: 'unlock', 1352: 'limped.', 1353: 'cares?', 1354: 'drove?', 1355: 'spoke?', 1356: 'she?', 1357: 'idiot!', 1358: 'early?', 1359: 'weird?', 1360: 'carry', 1361: 'choose', 1362: 'in!', 1363: 'jump!', 1364: 'jump.', 1365: 'talk!', 1366: 'burns.', 1367: 'life!', 1368: 'd.', 1369: 'north.', 1370: 'absurd!', 1371: 'disagree.', 1372: 'a.', 1373: 'amused.', 1374: 'sneaky.', 1375: 'twelve.', 1376: 'time?', 1377: 'matters.', 1378: 'fad.', 1379: 'begun.', 1380: 'bogus.', 1381: 'bulky.', 1382: 'green.', 1383: 'comment.', 1384: 'burped.', 1385: 'danced.', 1386: 'drives.', 1387: 'gasped.', 1388: 'phoned.', 1389: 'smoked.', 1390: 'yelled.', 1391: 'glad.', 1392: 'bit.', 1393: 'fun?', 1394: 'men.', 1395: 'boys.', 1396: 'even.', 1397: 'gives?', 1398: 'we?', 1399: 'phoned?', 1400: 'stayed?', 1401: 'talked?', 1402: 'yelled?', 1403: 'wood', 1404: 'called?', 1405: 'missed.', 1406: 'anyone', 1407: 'sensible.', 1408: 'boys', 1409: 'wait?', 1410: 'talk?', 1411: 'mind?', 1412: 'leave!', 1413: 'guts.', 1414: 'eight.', 1415: 'curious!', 1416: 'goes', 1417: 'online.', 1418: 'burned', 1419: 'dumb.', 1420: 'both.', 1421: 'jazz.', 1422: 'rock.', 1423: 'soup.', 1424: 'lips.', 1425: 'recovered.', 1426: 'ufo.', 1427: 'gas.', 1428: 'surrender.', 1429: 'won', 1430: 'cancel.', 1431: '17,', 1432: 'medic.', 1433: 'vegan.', 1434: 'certain.', 1435: 'chicken.', 1436: 'debt.', 1437: 'jealous.', 1438: 'popular.', 1439: 'praying.', 1440: 'resting.', 1441: 'selfish.', 1442: 'shocked.', 1443: 'law.', 1444: 'unarmed.', 1445: 'unlucky.', 1446: 'wealthy.', 1447: 'black?', 1448: 'tasty?', 1449: 'be!', 1450: 'foggy.', 1451: 'real.', 1452: 'locked.', 1453: 'use.', 1454: 'spring.', 1455: 'across.', 1456: 'money', 1457: 'means', 1458: 'grow.', 1459: 'spit', 1460: 'bite.', 1461: 'slower.', 1462: \"there's\", 1463: 'hugged.', 1464: 'blinked.', 1465: 'cheered.', 1466: 'drowned.', 1467: 'groaned.', 1468: 'ocd.', 1469: 'kneeled.', 1470: 'listens.', 1471: 'noticed.', 1472: 'replied.', 1473: 'tripped.', 1474: 'vomited.', 1475: 'flaky.', 1476: 'older.', 1477: 'cold?', 1478: 'split', 1479: 'pity!', 1480: 'escaped?', 1481: 'stopped?', 1482: 'going?', 1483: 'abandon', 1484: 'cops?', 1485: 'fair?', 1486: 'attentive.', 1487: 'fbi.', 1488: 'on,', 1489: 'quickly!', 1490: 'deal', 1491: 'bug', 1492: 'dress', 1493: 'warmly.', 1494: 'safely.', 1495: 'easy', 1496: 'easter!', 1497: 'courage.', 1498: 'heroic.', 1499: 'girls.', 1500: 'dare', 1501: 'chinese.', 1502: 'apologized.', 1503: 'pear.', 1504: 'lip.', 1505: 'cried,', 1506: 'dug', 1507: 'hole.', 1508: 'sushi.', 1509: 'cow.', 1510: 'improvised.', 1511: 'obeyed', 1512: 'piano.', 1513: 'seldom', 1514: 'slept', 1515: 'wonder', 1516: 'coward.', 1517: 'dancer.', 1518: 'father.', 1519: 'friend.', 1520: 'genius.', 1521: 'purist.', 1522: 'singer.', 1523: 'waiter.', 1524: 'actor.', 1525: 'drowning.', 1526: 'dyslexic.', 1527: 'eighteen.', 1528: 'fine', 1529: 'finished.', 1530: 'grateful.', 1531: 'homeless.', 1532: 'hungover.', 1533: 'paris.', 1534: 'innocent.', 1535: 'managing.', 1536: 'rebel.', 1537: 'offended.', 1538: 'positive.', 1539: 'rich', 1540: 'sleeping.', 1541: 'watching.', 1542: 'blind?', 1543: 'wolf?', 1544: 'nearby?', 1545: 'no?', 1546: 'blue?', 1547: 'real?', 1548: 'scares', 1549: 'empty.', 1550: 'shame.', 1551: 'awesome.', 1552: \"life's\", 1553: 'box.', 1554: 'fox.', 1555: 'shrieked.', 1556: 'filming.', 1557: 'dreams!', 1558: 'dreams.', 1559: 'command.', 1560: 'control.', 1561: 'easy!', 1562: 'right!', 1563: 'approves.', 1564: 'enlisted.', 1565: 'insisted.', 1566: 'frank.', 1567: 'vague.', 1568: 'meant', 1569: 'speak.', 1570: 'amazed.', 1571: 'filthy.', 1572: 'strict.', 1573: 'unbelievable!', 1574: 'funny?', 1575: 'scary?', 1576: 'news.', 1577: 'attack.', 1578: 'war.', 1579: 'doomed.', 1580: 'people.', 1581: 'loser!', 1582: 'shame!', 1583: 'cat?', 1584: 'tv?', 1585: 'they?', 1586: 'listened?', 1587: 'panicked?', 1588: 'survived?', 1589: 'vanished?', 1590: 'drive?', 1591: 'annoy', 1592: 'dirty.', 1593: 'lying!', 1594: 'questions?', 1595: 'fan?', 1596: 'security!', 1597: 'dance?', 1598: 'skate?', 1599: 'sleep?', 1600: 'check,', 1601: 'pot.', 1602: 'faint?', 1603: 'leave?', 1604: 'smile?', 1605: 'him?', 1606: 'favor.', 1607: 'dry', 1608: 'feed', 1609: 'bird.', 1610: 'watch.', 1611: 'caught.', 1612: 'sells', 1613: 'annoying.', 1614: 'tokyo.', 1615: 'comes.', 1616: 'nose', 1617: 'line.', 1618: 'be?', 1619: 'far', 1620: 'late', 1621: 'muslim.', 1622: 'coughing.', 1623: 'outraged.', 1624: 'deserved', 1625: 'dislike', 1626: 'dye', 1627: 'unwell.', 1628: 'freaked', 1629: 'flu.', 1630: 'clue.', 1631: 'hide.', 1632: 'boat.', 1633: 'fall.', 1634: 'garlic.', 1635: 'horses.', 1636: 'salmon.', 1637: 'skiing.', 1638: 'tennis.', 1639: 'supper.', 1640: 'resist.', 1641: 'taxi.', 1642: 'needed', 1643: 'violin.', 1644: 'plane.', 1645: 'someone.', 1646: 'house.', 1647: 'sold', 1648: 'support', 1649: 'volunteered.', 1650: 'pony.', 1651: 'excited.', 1652: 'invited.', 1653: 'page', 1654: 'dentist.', 1655: 'redhead.', 1656: 'shy', 1657: 'soldier.', 1658: 'tourist.', 1659: 'alone', 1660: 'beautiful.', 1661: 'busy,', 1662: 'dangerous.', 1663: 'depressed.', 1664: 'different.', 1665: 'expecting.', 1666: 'home,', 1667: 'danger.', 1668: 'listening.', 1669: 'miserable.', 1670: 'ready', 1671: 'asleep?', 1672: 'turn?', 1673: 'serious?', 1674: 'dog?', 1675: 'blood?', 1676: 'apart.', 1677: 'hurts', 1678: 'sickens', 1679: 'takes', 1680: 'gift.', 1681: 'lovely.', 1682: 'p.m.', 1683: 'saturday.', 1684: 'treat.', 1685: 'unlocked.', 1686: 'paddling.', 1687: 'finish.', 1688: 'proceed.', 1689: 'door!', 1690: 'cat', 1691: 'aches.', 1692: 'neck', 1693: 'no,', 1694: 'nothing', 1695: 'owls', 1696: 'people', 1697: 'aloud.', 1698: 'peace.', 1699: 'school', 1700: 'bent', 1701: 'temp.', 1702: 'active.', 1703: 'obeys', 1704: 'cutie.', 1705: 'together.', 1706: 'dreaming.', 1707: 'room.', 1708: 'tastes', 1709: 'fact.', 1710: 'hare.', 1711: 'brown.', 1712: 'closed', 1713: 'baby.', 1714: 'crafty.', 1715: 'frugal.', 1716: 'honest.', 1717: 'loving.', 1718: 'puking.', 1719: 'joined', 1720: 'taught', 1721: 'trusts', 1722: 'choking.', 1723: 'cooking.', 1724: 'engaged.', 1725: 'limping.', 1726: 'till', 1727: 'six.', 1728: 'joke?', 1729: 'caught', 1730: 'robbed.', 1731: 'tailors.', 1732: 'shot?', 1733: 'left?', 1734: 'her?', 1735: 'fasting?', 1736: 'winning?', 1737: 'whose', 1738: 'change', 1739: 'better', 1740: 'mail.', 1741: 'hypocrite!', 1742: 'morons.', 1743: 'cute?', 1744: 'hiring?', 1745: 'scared?', 1746: 'single?', 1747: 'down?', 1748: 'cage.', 1749: 'cows', 1750: 'forget?', 1751: \"dinner's\", 1752: 'want.', 1753: 'tempt', 1754: 'show.', 1755: 'fishing', 1756: 'form', 1757: 'lines.', 1758: 'towel.', 1759: 'bed!', 1760: 'rid', 1761: 'kiss.', 1762: 'year!', 1763: 'radio.', 1764: 'bankrupt.', 1765: 'face', 1766: 'learns', 1767: 'sang', 1768: 'song.', 1769: 'surrendered.', 1770: 'big', 1771: 'author.', 1772: 'comes', 1773: 'ached.', 1774: 'brakes.', 1775: 'deep', 1776: 'high', 1777: 'wide', 1778: 'accept', 1779: 'gifts.', 1780: 'bet', 1781: 'bike', 1782: 'arm.', 1783: 'jeans', 1784: 'mondays.', 1785: 'ironing.', 1786: 'parties.', 1787: 'spinach.', 1788: 'amnesia.', 1789: 'hurried', 1790: 'cookies.', 1791: 'lettuce.', 1792: 'mahjong.', 1793: 'oranges.', 1794: 'flowers.', 1795: 'raise.', 1796: 'hiccup.', 1797: 'past', 1798: 'her', 1799: 'korean.', 1800: 'sure', 1801: 'travel', 1802: 'turned', 1803: 'play.', 1804: 'confused.', 1805: 'poisoned.', 1806: 'wear', 1807: 'glasses.', 1808: 'rather', 1809: 'beginner.', 1810: 'botanist.', 1811: 'musician.', 1812: 'pacifist.', 1813: 'officer.', 1814: 'bored,', 1815: 'having', 1816: 'illiterate.', 1817: 'mad', 1818: 'meditating.', 1819: 'quitter.', 1820: 'overweight.', 1821: 'unlucky!', 1822: 'oldest.', 1823: 'thirty', 1824: 'untalented.', 1825: 'french', 1826: 'easy?', 1827: 'married?', 1828: 'doctor?', 1829: 'yet?', 1830: 'bird?', 1831: 'normal?', 1832: 'makes', 1833: 'sense.', 1834: 'sounds', 1835: 'ambush!', 1836: 'beyond', 1837: 'delicious.', 1838: 'posted.', 1839: 'boy', 1840: \"mum's\", 1841: 'sore.', 1842: 'seals', 1843: 'cooks', 1844: 'run!', 1845: 'duck!', 1846: 'wait!', 1847: 'oh', 1848: 'no!', 1849: 'cheers!', 1850: 'thanks!', 1851: 'awesome!', 1852: 'bury', 1853: 'fold', 1854: 'sad!', 1855: 'hit!', 1856: 'me,', 1857: 'perfect!', 1858: 'welcome.', 1859: 'won?', 1860: 'rise.', 1861: 'cheer', 1862: 'off!', 1863: 'real!', 1864: 'ahead!', 1865: 'deep?', 1866: 'nice!', 1867: 'resign.', 1868: 'helps.', 1869: 'marry', 1870: 'speed', 1871: 'went.', 1872: 'fun!', 1873: 'aim.', 1874: 'chill', 1875: 'bark.', 1876: 'hands', 1877: 'sexy.', 1878: '$5.', 1879: 'awful!', 1880: 'weird!', 1881: 'hurried.', 1882: 'sped', 1883: 'cured.', 1884: 'far?', 1885: 'red?', 1886: 'poured.', 1887: '3:30.', 1888: '8:30.', 1889: 'back!', 1890: 'shot!', 1891: '\"aah.\"', 1892: 'hello.', 1893: 'below.', 1894: 'care!', 1895: 'then', 1896: \"time's\", 1897: 'bowed.', 1898: 'cooks.', 1899: 'dived.', 1900: 'dozed.', 1901: 'knits.', 1902: 'rocks.', 1903: 'swims.', 1904: 'well', 1905: 'on?', 1906: 'stood?', 1907: 'aboard!', 1908: 'hired?', 1909: '18?', 1910: 'anyone.', 1911: 'careful!', 1912: 'bottoms', 1913: 'definitely!', 1914: 'destroy', 1915: 'dig', 1916: 'brag.', 1917: 'peek.', 1918: 'push.', 1919: 'rush.', 1920: 'duty', 1921: 'calls.', 1922: 'fill', 1923: 'exists.', 1924: 'faith.', 1925: 'swiss.', 1926: 'boring!', 1927: 'lovely!', 1928: 'tragic!', 1929: 'admit', 1930: 'chew', 1931: 'gum.', 1932: 'art.', 1933: 'air.', 1934: 'pity', 1935: 'wolf.', 1936: 'anemic.', 1937: 'baking.', 1938: 'buying.', 1939: 'humble.', 1940: 'hungry!', 1941: 'immune.', 1942: 'mature.', 1943: 'ruined.', 1944: 'sleepy!', 1945: 'eaten.', 1946: 'ill?', 1947: 'over?', 1948: 'clear.', 1949: 'shiny.', 1950: 'windy.', 1951: 'jesus', 1952: 'quiet!', 1953: 'pray.', 1954: 'vote.', 1955: 'lasts.', 1956: 'mama', 1957: 'mind!', 1958: 'problem!', 1959: 'scoot', 1960: 'shadow', 1961: 'sing', 1962: 'boy!', 1963: 'agrees.', 1964: 'braked.', 1965: 'cooked.', 1966: 'dances.', 1967: 'drinks.', 1968: 'fought.', 1969: 'goofed.', 1970: 'looked.', 1971: 'paints.', 1972: 'sighed.', 1973: 'smokes.', 1974: 'snores.', 1975: 'sobbed.', 1976: 'tough', 1977: 'luck!', 1978: 'unscrew', 1979: 'cds.', 1980: 'row?', 1981: 'bother?', 1982: 'shy?', 1983: 'anybody.', 1984: 'generous.', 1985: 'tolerant.', 1986: 'watchful.', 1987: \"beer's\", 1988: 'run?', 1989: 'again!', 1990: 'fish?', 1991: 'blink.', 1992: 'panic!', 1993: 'panic.', 1994: 'dressed.', 1995: 'met?', 1996: 'come!', 1997: 'jerk.', 1998: 'faking.', 1999: 'loaded.', 2000: 'are!', 2001: 'bag.', 2002: 'life?', 2003: 'strange!', 2004: 'taller.', 2005: 'assume', 2006: 'class.', 2007: 'fired', 2008: 'forgot', 2009: 'bugs.', 2010: 'mice.', 2011: '$300.', 2012: 'ptsd.', 2013: 'beef.', 2014: 'glue.', 2015: 'oppose', 2016: 'stammered.', 2017: 'follow.', 2018: 'baker.', 2019: 'child.', 2020: 'klutz.', 2021: 'loner.', 2022: 'slave.', 2023: 'finicky.', 2024: 'jail.', 2025: 'sad', 2026: 'sincere.', 2027: 'starved.', 2028: 'stuffed!', 2029: 'through.', 2030: 'touched.', 2031: 'trapped.', 2032: 'foggy?', 2033: 'white?', 2034: 'windy?', 2035: 'art?', 2036: '50', 2037: 'yen.', 2038: 'bull.', 2039: 'rule.', 2040: 'cloudy.', 2041: 'futile.', 2042: 'poison.', 2043: 'split.', 2044: 'wish.', 2045: 'talks.', 2046: 'timing.', 2047: 'move!', 2048: 'plants', 2049: 'clap.', 2050: 'hold.', 2051: 'press', 2052: 'curt.', 2053: 'still!', 2054: 'moving!', 2055: 'thief!', 2056: 'tea,', 2057: 'huge.', 2058: \"tv's\", 2059: 'kissed.', 2060: 'belched.', 2061: 'decided.', 2062: 'exhaled.', 2063: 'gloated.', 2064: 'grinned.', 2065: 'inhaled.', 2066: 'slim.', 2067: 'painted.', 2068: 'prepaid.', 2069: 'sneezed.', 2070: 'teaches.', 2071: 'alert.', 2072: 'cnn.', 2073: 'hell.', 2074: 'meet.', 2075: 'stole', 2076: 'share.', 2077: 'saved.', 2078: 'bore!', 2079: 'dump.', 2080: 'game!', 2081: 'loss!', 2082: 'mess!', 2083: 'team!', 2084: 'ego!', 2085: \"where's\", 2086: 'cheered?', 2087: 'floats.', 2088: 'yes,', 2089: 'sick!', 2090: 'ship!', 2091: 'ship.', 2092: 'invited?', 2093: 'broke?', 2094: 'bald?', 2095: 'deaf?', 2096: 'okay?', 2097: 'rich?', 2098: 'tidy?', 2099: 'realistic!', 2100: 'beef,', 2101: 'backup.', 2102: 'move?', 2103: 'ten.', 2104: 'describe', 2105: 'fall?', 2106: 'pray?', 2107: 'call?', 2108: 'sign?', 2109: 'agree?', 2110: 'drink?', 2111: 'show?', 2112: 'fish,', 2113: 'roof.', 2114: 'food', 2115: 'out,', 2116: 'ghosts', 2117: 'exist.', 2118: 'around', 2119: 'away,', 2120: 'evening.', 2121: 'goodbye,', 2122: 'grow', 2123: 'donut.', 2124: 'snack.', 2125: 'taste.', 2126: 'kicked', 2127: 'bigot.', 2128: 'ninja.', 2129: 'honesty', 2130: 'pays.', 2131: 'arrogant!', 2132: 'barbaric!', 2133: 'exciting!', 2134: 'horrible!', 2135: 'pathetic!', 2136: 'romantic!', 2137: 'touching!', 2138: 'caviar.', 2139: 'burp', 2140: 'draw.', 2141: 'detest', 2142: 'cuss.', 2143: 'faint.', 2144: 'giddy.', 2145: 'fought', 2146: 'jogging.', 2147: 'beans.', 2148: 'liars.', 2149: 'tests.', 2150: 'hives.', 2151: 'knelt', 2152: 'honey.', 2153: 'sugar.', 2154: 'trees.', 2155: 'women.', 2156: 'games.', 2157: 'jokes.', 2158: 'trips.', 2159: 'paint.', 2160: 'phoned', 2161: 'rarely', 2162: 'robbed', 2163: 'lion.', 2164: 'star.', 2165: 'smelled', 2166: 'suppose', 2167: 'swim', 2168: 'teased', 2169: 'understand.', 2170: 'facts.', 2171: 'shaken.', 2172: 'lose!', 2173: '99%', 2174: 'pisces.', 2175: 'client.', 2176: 'farmer.', 2177: 'hunter.', 2178: 'mother.', 2179: 'person.', 2180: 'anorexic.', 2181: 'artistic.', 2182: 'bleeding.', 2183: 'bluffing.', 2184: 'escaping.', 2185: 'expected.', 2186: 'fat,', 2187: 'grounded.', 2188: 'gullible.', 2189: 'horrible.', 2190: 'perth.', 2191: 'angel.', 2192: 'poor', 2193: 'pregnant.', 2194: 'reliable.', 2195: 'restless.', 2196: 'tired!', 2197: 'speaking.', 2198: 'standing.', 2199: 'starving.', 2200: 'stronger.', 2201: 'stubborn.', 2202: 'thirteen.', 2203: 'ticklish.', 2204: 'worn', 2205: 'checked.', 2206: 'ice', 2207: 'solid.', 2208: 'iron', 2209: 'monday', 2210: 'lucid?', 2211: 'lying?', 2212: 'deer?', 2213: 'broken?', 2214: 'cancer?', 2215: 'salt?', 2216: 'snow?', 2217: 'wine?', 2218: 'scared', 2219: 'october.', 2220: 'glove.', 2221: 'plant.', 2222: 'snail.', 2223: 'steal.', 2224: 'bizarre.', 2225: 'hailing.', 2226: 'hearsay.', 2227: 'immoral.', 2228: 'morning.', 2229: 'ladies', 2230: 'lead', 2231: 'math', 2232: 'meat,', 2233: 'pigs.', 2234: 'cry,', 2235: 'hurry?', 2236: 'arm', 2237: 'ears', 2238: 'hip', 2239: 'objection.', 2240: 'cared.', 2241: 'asked.', 2242: 'met.', 2243: \"school's\", 2244: 'then.', 2245: 'sued', 2246: 'babe.', 2247: 'louder.', 2248: 'softly.', 2249: 'while.', 2250: 'gawking.', 2251: 'staring.', 2252: 'stop,', 2253: 'tickles.', 2254: 'pass.', 2255: 'lot!', 2256: 'great!', 2257: 'trash.', 2258: \"they've\", 2259: 'just.', 2260: 'answered.', 2261: 'approved.', 2262: 'flinched.', 2263: 'followed.', 2264: 'acne.', 2265: 'vet.', 2266: 'frail.', 2267: 'heavy.', 2268: 'loyal.', 2269: 'messy.', 2270: 'ex.', 2271: 'stoic.', 2272: 'three.', 2273: 'screamed.', 2274: 'shivered.', 2275: 'shrugged.', 2276: 'stutters.', 2277: 'nosy.', 2278: 'wary.', 2279: 'silent.', 2280: 'god.', 2281: 'seen?', 2282: 'arabs.', 2283: 'starve.', 2284: 'closed.', 2285: 'dating.', 2286: 'heroes.', 2287: 'humans.', 2288: 'nerve!', 2289: 'night!', 2290: 'woman!', 2291: 'ufo?', 2292: 'canceled?', 2293: 'pay?', 2294: 'fight?', 2295: 'buying?', 2296: 'paying?', 2297: 'wish', 2298: 'luck.', 2299: 'years', 2300: 'passed.', 2301: 'how.', 2302: 'put.', 2303: 'gross.', 2304: 'salt.', 2305: 'approved?', 2306: 'dreaming?', 2307: 'mistaken?', 2308: 'slipping?', 2309: 'else?', 2310: 'brave?', 2311: 'short?', 2312: 'baking', 2313: 'reasonable.', 2314: 'bolt', 2315: 'cain', 2316: 'tango?', 2317: 'chess', 2318: 'click', 2319: 'edit.', 2320: 'right', 2321: 'visit', 2322: 'cover', 2323: 'dance', 2324: 'drown?', 2325: 'laugh?', 2326: 'reply?', 2327: 'speak?', 2328: 'daft.', 2329: 'mock', 2330: 'respond.', 2331: 'draw', 2332: 'circle.', 2333: 'gun!', 2334: 'healthily.', 2335: 'peas.', 2336: 'wins.', 2337: 'exhale', 2338: 'clock.', 2339: 'flowers', 2340: 'bloom.', 2341: 'flying', 2342: 'fry', 2343: 'few.', 2344: 'without', 2345: 'there!', 2346: 'ham.', 2347: 'advises', 2348: 'cheated', 2349: 'eats', 2350: 'feels', 2351: 'grows', 2352: 'blog.', 2353: 'ignored', 2354: 'british.', 2355: 'thief.', 2356: 'falling.', 2357: 'foolish.', 2358: 'type!', 2359: 'lots.', 2360: 'cars.', 2361: 'tricked', 2362: 'walks', 2363: 'austrian.', 2364: 'jesuit.', 2365: 'autistic.', 2366: 'friendly.', 2367: 'hens', 2368: '$10.00.', 2369: 'everybody.', 2370: 'bled.', 2371: 'bad', 2372: 'beautiful!', 2373: 'thrilling!', 2374: 'lunch?', 2375: 'admired', 2376: 'sneezing.', 2377: 'belong', 2378: 'biked', 2379: 'blacked', 2380: 'caused', 2381: 'contributed.', 2382: 'cough', 2383: \"couldn't\", 2384: 'despise', 2385: 'disliked', 2386: 'juice.', 2387: 'dream', 2388: 'chess.', 2389: 'exaggerated.', 2390: 'fed', 2391: 'queasy.', 2392: 'forgave', 2393: 'celery.', 2394: 'date.', 2395: 'ring.', 2396: 'visa.', 2397: 'cancer.', 2398: 'orders.', 2399: 'sinned.', 2400: 'voices.', 2401: 'kid', 2402: 'things.', 2403: 'clocks.', 2404: 'donuts.', 2405: 'reggae.', 2406: 'soccer.', 2407: 'spoons.', 2408: 'trains.', 2409: 'tulips.', 2410: 'yellow.', 2411: 'monday!', 2412: 'autumn.', 2413: 'camels.', 2414: 'nature.', 2415: 'pandas.', 2416: 'plants.', 2417: 'dinner.', 2418: 'married', 2419: 'nearly', 2420: 'crew.', 2421: 'loan.', 2422: 'stamps.', 2423: 'rely', 2424: 'rescued', 2425: 'respect', 2426: 'mouse!', 2427: 'crown.', 2428: 'woman.', 2429: 'rat.', 2430: 'can.', 2431: 'twitter.', 2432: 'visited', 2433: 'pool.', 2434: 'bullied.', 2435: 'furious.', 2436: 'naughty.', 2437: 'pleased.', 2438: 'tempted.', 2439: 'told.', 2440: 'hiking.', 2441: 'nights.', 2442: 'poems.', 2443: 'songs.', 2444: 'colonel.', 2445: 'cripple.', 2446: 'fireman.', 2447: 'painter.', 2448: 'suspect.', 2449: 'addict.', 2450: 'orphan.', 2451: 'angry', 2452: 'awake', 2453: 'coming', 2454: 'concerned.', 2455: 'convinced.', 2456: 'dedicated.', 2457: 'easygoing.', 2458: 'flattered.', 2459: 'giving', 2460: 'mom!', 2461: 'impatient.', 2462: 'impressed.', 2463: 'gang.', 2464: 'denial.', 2465: 'motivated.', 2466: 'angry!', 2467: 'diet.', 2468: 'own.', 2469: 'satisfied.', 2470: 'saying', 2471: 'screaming.', 2472: 'skeptical.', 2473: 'surprised.', 2474: 'coach.', 2475: 'unmarried.', 2476: 'returned.', 2477: 'around?', 2478: 'eating?', 2479: 'guilty?', 2480: 'llama?', 2481: 'helping?', 2482: 'popular?', 2483: 'snowing?', 2484: 'strange?', 2485: 'bat?', 2486: 'lot?', 2487: 'wig?', 2488: 'yes?', 2489: 'clear?', 2490: 'sugar?', 2491: 'sweet?', 2492: 'more?', 2493: 'flat?', 2494: 'trap.', 2495: 'chilly.', 2496: 'ironic.', 2497: 'superb.', 2498: '2:00', 2499: '8:00', 2500: 'fungus.', 2501: 'relief.', 2502: 'accurate.', 2503: 'honor.', 2504: 'order.', 2505: 'business.', 2506: 'dark', 2507: 'exciting.', 2508: 'fall', 2509: 'gorgeous.', 2510: 'homemade.', 2511: 'hopeless.', 2512: 'improved.', 2513: 'inhumane.', 2514: 'midnight.', 2515: 'obsolete.', 2516: 'occupied.', 2517: 'optional.', 2518: 'possible.', 2519: 'cops!', 2520: 'unlikely.', 2521: 'touch!', 2522: 'touch.', 2523: 'look!', 2524: 'kitty!', 2525: 'beds.', 2526: 'mortal.', 2527: \"mom's\", 2528: 'motion', 2529: 'denied.', 2530: \"hair's\", 2531: 'knee', 2532: \"name's\", 2533: 'pen', 2534: 'night', 2535: \"didn't.\", 2536: 'team', 2537: 'pass', 2538: 'robe.', 2539: 'quiet,', 2540: 'stalling.', 2541: 'remain', 2542: 'rest', 2543: 'type.', 2544: 'beside', 2545: 'clearly.', 2546: 'ease!', 2547: 'hydrated.', 2548: 'stir', 2549: 'babbling.', 2550: 'bragging.', 2551: 'chatting.', 2552: 'fighting!', 2553: 'laughing.', 2554: 'meddling.', 2555: 'shouting.', 2556: 'straighten', 2557: \"summer's\", 2558: 'sweep', 2559: 'shower.', 2560: 'differ.', 2561: 'saturn.', 2562: 'copy.', 2563: 'doll.', 2564: 'myth.', 2565: 'risk.', 2566: 'sign.', 2567: 'tree.', 2568: 'doable.', 2569: 'untrue.', 2570: 'bell', 2571: 'rang.', 2572: 'cup', 2573: 'asian.', 2574: 'fools.', 2575: 'spies.', 2576: 'japan.', 2577: 'dvd.', 2578: 'pun.', 2579: 'end.', 2580: 'throw', 2581: 'blames', 2582: 'exercises.', 2583: 'brat.', 2584: 'chef.', 2585: 'jock.', 2586: 'slob.', 2587: 'wimp.', 2588: 'absent.', 2589: 'clever.', 2590: 'dreamy.', 2591: 'nearby.', 2592: 'normal.', 2593: 'stingy.', 2594: 'touchy.', 2595: 'left,', 2596: 'rum.', 2597: 'opened', 2598: 'pays', 2599: 'protested.', 2600: 'pushed', 2601: 'raised', 2602: 'remembers.', 2603: 'staggered.', 2604: 'struggled.', 2605: 'texted', 2606: 'warned', 2607: 'quick.', 2608: 'weary.', 2609: 'mute.', 2610: 'west.', 2611: 'would', 2612: 'zoomed', 2613: 'adopted.', 2614: 'amazing.', 2615: 'annoyed.', 2616: 'anxious.', 2617: 'elderly.', 2618: 'helping.', 2619: 'missing.', 2620: 'packing.', 2621: 'violent.', 2622: 'yelling.', 2623: 'page.', 2624: 'feet.', 2625: 'dear.', 2626: 'snoring?', 2627: 'wax', 2628: 'floor.', 2629: 'assumed', 2630: 'end', 2631: 'drove', 2632: 'rules.', 2633: 'focus.', 2634: 'saw.', 2635: 'paper.', 2636: 'space.', 2637: 'tools.', 2638: 'started', 2639: 'succeed.', 2640: 'cousins.', 2641: 'dancers.', 2642: 'doctors.', 2643: 'enemies.', 2644: 'kidding.', 2645: 'parents.', 2646: 'sinking.', 2647: 'special.', 2648: 'stalled.', 2649: 'trapped!', 2650: 'waiting.', 2651: 'winners.', 2652: 'done', 2653: 'hassle!', 2654: 'relief!', 2655: 'get?', 2656: 'owe?', 2657: 'truth?', 2658: 'nonsense!', 2659: \"what'll\", 2660: 'elf?', 2661: 'inside?', 2662: 'when', 2663: \"when's\", 2664: 'dinner?', 2665: 'which', 2666: 'disagreed?', 2667: 'remembers?', 2668: 'responded?', 2669: 'says', 2670: 'succeeded?', 2671: 'tea?', 2672: 'dieting?', 2673: 'humming?', 2674: 'missing?', 2675: 'staying?', 2676: 'talking?', 2677: 'thirsty?', 2678: 'women', 2679: 'ruined', 2680: 'far.', 2681: 'sweaty.', 2682: 'beer,', 2683: \"car's\", 2684: 'coke,', 2685: 'fight', 2686: 'ensued.', 2687: 'act', 2688: 'you,', 2689: \"ain't\", 2690: 'babies', 2691: 'suspect?', 2692: 'qualified?', 2693: 'apples', 2694: 'kids?', 2695: 'leaving?', 2696: 'sinking?', 2697: 'hiding?', 2698: 'honest?', 2699: 'polite?', 2700: 'sad?', 2701: 'autumn', 2702: 'optimist.', 2703: 'careful', 2704: 'blow', 2705: 'nose.', 2706: 'boats', 2707: 'sink.', 2708: 'both', 2709: 'brace', 2710: 'frank?', 2711: 'see,', 2712: 'everyone.', 2713: 'coffee,', 2714: 'comb', 2715: 'copy', 2716: 'file.', 2717: 'grass.', 2718: 'nails.', 2719: 'death', 2720: 'escape?', 2721: 'notice?', 2722: 'object?', 2723: 'like.', 2724: 'now,', 2725: 'tigers', 2726: 'purr?', 2727: 'snore?', 2728: 'complain.', 2729: 'obey', 2730: 'knife!', 2731: 'dude,', 2732: 'salad.', 2733: 'dies.', 2734: 'flies', 2735: 'van.', 2736: 'kick.', 2737: 'week.', 2738: 'bed,', 2739: 'park.', 2740: 'golf', 2741: 'afternoon.', 2742: 'work,', 2743: 'birthday!', 2744: 'holidays.', 2745: 'also', 2746: 'to.', 2747: 'count.', 2748: 'confused', 2749: 'disappeared.', 2750: 'dislikes', 2751: 'drives', 2752: 'uneasy.', 2753: 'flew', 2754: '12', 2755: 'sons.', 2756: 'point.', 2757: 'fear.', 2758: 'american.', 2759: 'writer.', 2760: 'delicate.', 2761: 'enemy.', 2762: 'uncle.', 2763: 'outgoing.', 2764: 'powerful.', 2765: 'keeps', 2766: 'lives', 2767: 'stern.', 2768: 'owes', 2769: 'respects', 2770: 'scolded', 2771: 'panting.', 2772: 'butcher.', 2773: 'fanatic.', 2774: 'gambler.', 2775: 'samurai.', 2776: 'slacker.', 2777: 'animal.', 2778: 'ex-con.', 2779: 'outlaw.', 2780: 'henpecked.', 2781: 'prison.', 2782: 'son', 2783: 'brakes!', 2784: 'doing?', 2785: 'things?', 2786: 'end?', 2787: 'disgusting!', 2788: 'exhausting!', 2789: 'long', 2790: 'lucky', 2791: 'am!', 2792: 'much', 2793: 'perceptive!', 2794: 'tall', 2795: 'boston?', 2796: 'wife?', 2797: 'guys.', 2798: 'danish.', 2799: 'banana.', 2800: 'apple.', 2801: 'much.', 2802: 'began', 2803: 'borrow', 2804: 'leg.', 2805: 'brought', 2806: 'changed', 2807: 'cycled', 2808: 'despised', 2809: 'flunk.', 2810: 'reply.', 2811: 'that,', 2812: 'gamble.', 2813: 'gossip.', 2814: 'recall.', 2815: 'tomatoes.', 2816: 'enjoyed', 2817: 'seasick.', 2818: 'church.', 2819: 'letter.', 2820: 'guarantee', 2821: 'stroke.', 2822: 'fun', 2823: 'insects.', 2824: 'karaoke.', 2825: 'riddles.', 2826: 'spiders.', 2827: '13', 2828: 'cough.', 2829: 'fever.', 2830: 'hunch.', 2831: 'knife.', 2832: 'table.', 2833: 'sisters.', 2834: 'so,', 2835: 'foot.', 2836: 'guessed.', 2837: 'diary.', 2838: 'kneeled', 2839: 'castles.', 2840: 'drawing.', 2841: 'ketchup.', 2842: 'name.', 2843: 'noodles.', 2844: 'oysters.', 2845: 'sashimi.', 2846: 'seafood.', 2847: 'stories.', 2848: 'sun.', 2849: 'hunt.', 2850: 'turtles.', 2851: 'harvard.', 2852: 'almonds.', 2853: 'animals.', 2854: 'bananas.', 2855: 'carrots.', 2856: 'dessert.', 2857: 'kittens.', 2858: 'lasagna.', 2859: 'lizards.', 2860: 'city.', 2861: 'ipod.', 2862: 'puzzles.', 2863: 'sunsets.', 2864: 'sea.', 2865: 'college.', 2866: 'decline.', 2867: 'broom.', 2868: 'hobby.', 2869: 'plate.', 2870: 'stamp.', 2871: 'answers.', 2872: 'keys.', 2873: 'privacy.', 2874: 'support.', 2875: 'surgery.', 2876: 'noticed', 2877: 'travel.', 2878: '$100.', 2879: 'taxes.', 2880: 'plead', 2881: 'promised', 2882: 'raise', 2883: 'cattle.', 2884: 'rejected', 2885: 'rewarded', 2886: 'five', 2887: 'somebody.', 2888: 'serve', 2889: 'sneeze', 2890: 'suggested', 2891: 'light.', 2892: 'usually', 2893: 'chair.', 2894: 'glass.', 2895: 'puppy.', 2896: 'justice.', 2897: 'popcorn.', 2898: 'revenge.', 2899: 'fan.', 2900: 'idiot.', 2901: 'captured.', 2902: 'detained.', 2903: 'homesick.', 2904: 'impolite.', 2905: 'outdoors.', 2906: 'sweating.', 2907: 'tortured.', 2908: 'loved.', 2909: 'prosper.', 2910: 'return.', 2911: 'come,', 2912: 'handle', 2913: 'pray', 2914: 'risk', 2915: 'scold', 2916: 'shoot', 2917: 'treat', 2918: 'aunt.', 2919: 'gardener.', 2920: 'mechanic.', 2921: 'real', 2922: 'stuntman.', 2923: 'teenager.', 2924: 'weakling.', 2925: 'against', 2926: 'atheist.', 2927: 'behind', 2928: 'being', 2929: 'used.', 2930: 'bored', 2931: 'dead', 2932: 'devastated.', 2933: 'diplomatic.', 2934: 'eating', 2935: 'famous', 2936: 'farsighted.', 2937: 'fascinated.', 2938: 'getting', 2939: 'going,', 2940: 'happy,', 2941: 'human,', 2942: 'hungry', 2943: 'trouble.', 2944: 'interested.', 2945: 'making', 2946: 'holiday.', 2947: 'overworked.', 2948: 'reading', 2949: 'sorry,', 2950: 'stuck', 2951: 'successful.', 2952: 'tired,', 2953: 'undressing.', 2954: 'unemployed.', 2955: 'seen.', 2956: 'stew.', 2957: 'moved', 2958: 'remarried.', 2959: 'solved', 2960: 'boston', 2961: 'adopted?', 2962: 'pain?', 2963: 'jealous?', 2964: 'nervous?', 2965: 'outside?', 2966: 'retired?', 2967: 'singing?', 2968: 'smiling?', 2969: 'american?', 2970: 'japanese?', 2971: 'sleeping?', 2972: 'secret?', 2973: 'weapon?', 2974: 'apple?', 2975: 'away?', 2976: 'possible?', 2977: 'much?', 2978: 'worth', 2979: 'bear?', 2980: 'fact?', 2981: 'hint?', 2982: 'mole?', 2983: 'better?', 2984: 'coffee?', 2985: 'hat?', 2986: 'mug?', 2987: 'fee?', 2988: 'great?', 2989: 'costs', 2990: 'disgusts', 2991: 'stinks', 2992: 'christmas.', 2993: 'wednesday.', 2994: 'bargain.', 2995: 'classic.', 2996: 'firefly.', 2997: 'admirable.', 2998: 'insult.', 2999: 'confusing.', 3000: 'difficult.', 3001: 'foggy', 3002: 'forbidden.', 3003: 'grotesque.', 3004: 'incorrect.', 3005: 'marvelous.', 3006: 'blood.', 3007: '3.', 3008: 'redundant.', 3009: 'truth.', 3010: 'their', 3011: 'large.', 3012: 'risky.', 3013: 'wonderful.', 3014: 'searching.', 3015: 'kids', 3016: 'kissing', 3017: 'large', 3018: 'small?', 3019: 'alone!', 3020: 'answer.', 3021: 'continue.', 3022: 'meet', 3023: 'practice.', 3024: 'louder,', 3025: 'two.', 3026: 'lying', 3027: 'blonde.', 3028: 'maybe', 3029: 'meat', 3030: 'scarce.', 3031: 'idiots.', 3032: 'power.', 3033: 'needed.', 3034: 'chest', 3035: 'desk', 3036: \"dog's\", 3037: 'donkey', 3038: 'hair', 3039: 'heart', 3040: 'joints', 3041: 'ache.', 3042: 'name', 3043: 'itches.', 3044: 'plan', 3045: \"tire's\", 3046: 'flat.', 3047: 'tooth', 3048: 'wife', 3049: 'wrist', 3050: \"nobody'll\", 3051: 'pout.', 3052: 'ow!', 3053: 'hurts!', 3054: 'pack', 3055: 'gear.', 3056: 'pigs', 3057: 'tune.', 3058: 'bill', 3059: 'prepare', 3060: 'prices', 3061: 'sailing', 3062: 'science', 3063: 'order?', 3064: 'choked', 3065: 'fooled', 3066: 'brains.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targ_vocab.index_word[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9ytd0YvmEXqK",
        "outputId": "0d39f387-ab93-44e5-f1f7-e63c7aff14bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start>'"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_vec.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjhT8KuHPF2O",
        "outputId": "dc530345-0b1c-4338-b7a9-cd1828feaca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing completed.\n",
        "\n"
      ],
      "metadata": {
        "id": "jsi0rNWLVFV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "input_train, input_test, target_train, target_test = train_test_split(inp_vec, targ_vec, test_size=0.2)"
      ],
      "metadata": {
        "id": "fYP3_iTlVKiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtP6Xl3yIf07",
        "outputId": "d846b051-f1e2-4920-8798-cd1db5d8cd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configuring model paramaters\n",
        "\n",
        "BUFFER_SIZE = len(input_train)\n",
        "BATCH_SIZE = 64 #training batch size\n",
        "iter_per_epoch = len(input_train)/64\n",
        "embedding_dim = 256\n",
        "units = 1024 #hidden\n",
        "vocab_inp_size = len(inp_vocab.word_index) + 1\n",
        "vocab_tar_size = len(targ_vocab.word_index) + 1"
      ],
      "metadata": {
        "id": "JbdagizOVsY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_train, target_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "hwgcL4nkmwez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yl6wfAT0m9w0",
        "outputId": "64f1b28e-5dce-45b9-875f-92e045b3251c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 7), (64, 11)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch, target_batch = next(iter(dataset))\n",
        "input_batch.shape, target_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmT3iai6nVMN",
        "outputId": "863c33fb-28ef-43dd-ff88-956458d71d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 7]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qx-T3ijneqs",
        "outputId": "810f79a9-c4ce-427a-ad57-a5846aa48ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([   1,   19, 1214,   10,    2,    0,    0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder Class"
      ],
      "metadata": {
        "id": "h67hnPWTfzkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_hidden_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_hidden_units = enc_hidden_units\n",
        "\n",
        "    # embedding layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # GRU Layer\n",
        "\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_hidden_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Encoder network comprises an Embedding layer followed by a GRU layer\n",
        "  def call(self, input, hidden):\n",
        "    #input first passed through embedding layer, then GRU layer\n",
        "    input = self.embedding(input)\n",
        "    output, state = self.gru(input, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  # To initialize the hidden state\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_hidden_units))"
      ],
      "metadata": {
        "id": "8tvm6YyunjA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(input_batch, sample_hidden)\n",
        "\n",
        "sample_output.shape, sample_hidden.shape\n",
        "\n",
        "#sample output shape: [batch size, input seq length, hidden units]\n",
        "#sample hidden state shape: [batch size, hidden units]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-oP_NLHqTvU",
        "outputId": "e8f85db7-126e-48b0-8274-c61b62508f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 7, 1024]), TensorShape([64, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention Mechanism"
      ],
      "metadata": {
        "id": "eT3xij6Rf46-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building Bahdanau Attention Mechanism\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, window_size):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.L1 = tf.keras.layers.Dense(window_size) #first layer for decoder hidden state\n",
        "    self.L2 = tf.keras.layers.Dense(window_size) #second layer for encoder outputs\n",
        "    self.final_layer = tf.keras.layers.Dense(1) #fully connected layer, both the layer are added,\n",
        "                                          #and go through a tan activation function\n",
        "\n",
        "  def call(self, decoder_hidden, encoder_output):\n",
        "\n",
        "    #to broadcast addition along time axis, for calculating the score\n",
        "    decoder_hidden_with_time = tf.expand_dims(decoder_hidden, 1) #shape: [batch size, 1, hidden units]\n",
        "\n",
        "    #now decoder hidden state and encoder output will go through tan activation function\n",
        "    #this happens in the fully connected layer\n",
        "    score = self.final_layer(tf.nn.tanh(self.L1(decoder_hidden_with_time) + self.L2(encoder_output)))\n",
        "\n",
        "    #attention weights calculated by softmax function\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    #calculate context vector\n",
        "    context_vector1 = attention_weights*encoder_output\n",
        "    #we added the vectors along the axis\n",
        "    context_vector = tf.reduce_sum(context_vector1, axis=1)\n",
        "\n",
        "    return attention_weights, context_vector1, context_vector"
      ],
      "metadata": {
        "id": "8JrNnNeZ4iFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention = BahdanauAttention(10)\n",
        "weights, context_vec_intermediate, context_vect = attention(sample_hidden, sample_output)"
      ],
      "metadata": {
        "id": "FRbG_qiFPQ47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#context_vec was calculated by attention_weight*sample_output\n",
        "weights.shape, sample_output.shape, context_vec_intermediate.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibhPrNzGdGtJ",
        "outputId": "1cf7eb01-2787-49b4-f237-9cc384fb725d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 7, 1]),\n",
              " TensorShape([64, 7, 1024]),\n",
              " TensorShape([64, 7, 1024]))"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vect.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04k_1rrhdUxL",
        "outputId": "c49e1d30-1011-4c87-8ceb-1b1012eec550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder Class"
      ],
      "metadata": {
        "id": "FDxDYsnyf9_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pass the input through embedding layer\n",
        "#then context layer is concatenated, passed through GRU layer\n",
        "#then passed into the fully connected layer\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_hidden_units, batch_sz):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.dec_hidden_units = dec_hidden_units\n",
        "    self.batch_sz = batch_sz\n",
        "\n",
        "    # embedding layer\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    #GRU layer\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_hidden_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "    #fully connected layer, this is a dense layer\n",
        "    self.fully_connected = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    #for context vector, attention output\n",
        "    self.attention = BahdanauAttention(self.dec_hidden_units)\n",
        "\n",
        "  def call(self, input, hidden, enc_output):\n",
        "    attention_weights, _, context_vec = self.attention(hidden, enc_output)\n",
        "\n",
        "    #input will pass throught embedding layer\n",
        "    input = self.embedding(input)\n",
        "\n",
        "    #concatenate with context vector\n",
        "    input = tf.concat([tf.expand_dims(context_vec, 1), input], axis=-1)\n",
        "\n",
        "    #passing input through GRU layer\n",
        "\n",
        "    output, states = self.gru(input) #shape: [batch_size, seq_length, hidden_units]\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    #pass the output throught fully connected layer\n",
        "    final_output = self.fully_connected(output)\n",
        "\n",
        "    return final_output, states\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3jFrqbu8f9eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "decoder_output, hidden_state = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)"
      ],
      "metadata": {
        "id": "7Idu2iw7fuH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_tar_size, decoder_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soZUNp_QajYi",
        "outputId": "aa49354b-3723-4650-ff24-9cacf4c61a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4997, TensorShape([64, 4997]))"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function"
      ],
      "metadata": {
        "id": "SVLiguNkfpQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#will be using adam optimiser\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "# Loss function\n",
        "def loss_function(real, pred):\n",
        "\n",
        "  # Since sentences were not of equal length, we did padding\n",
        "  # If there's a '0' in the sequence, the loss is being nullified\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "YfNsKUgsatNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "0dH5L1meinYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    # <start> is the first decoder input\n",
        "    dec_input = tf.expand_dims([targ_vocab.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "\n",
        "      # Pass enc_output to the decoder\n",
        "      predictions, dec_hidden = decoder(dec_input, hidden, enc_output)\n",
        "\n",
        "      # Compute the loss\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Use teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  # As this function is called per batch, compute the batch_loss\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  # Get the model's variables\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  # Compute the gradients\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  # Update the variables of the model/network\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "metadata": {
        "id": "KbmiCiUQgAB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(int(iter_per_epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvtff6mSmL0i",
        "outputId": "97bcca19-43f5-4012-dcda-a3713586320e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((64, 7), (64, 11)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int(iter_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApGR94w2n1j6",
        "outputId": "a57080e1-0c3b-416d-8829-b2b59acf56a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  # Initialize the hidden state\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  # Loop through the dataset\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(int(iter_per_epoch))):\n",
        "\n",
        "    # Call the train method\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "\n",
        "    # Compute the loss (per batch)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "\n",
        "  # Output the loss observed until that epoch\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / iter_per_epoch))\n",
        "  \n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f8kbLJAlMTl",
        "outputId": "fa6d77e9-4449-473e-d209-a3c7184ece99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 3.4233\n",
            "Epoch 1 Batch 100 Loss 1.9615\n",
            "Epoch 1 Loss 2.0434\n",
            "Time taken for 1 epoch 441.9445195198059 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.6276\n",
            "Epoch 2 Batch 100 Loss 1.4435\n",
            "Epoch 2 Loss 1.5594\n",
            "Time taken for 1 epoch 411.04077196121216 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.3184\n",
            "Epoch 3 Batch 100 Loss 1.3920\n",
            "Epoch 3 Loss 1.3385\n",
            "Time taken for 1 epoch 441.9105978012085 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1486\n",
            "Epoch 4 Batch 100 Loss 1.1733\n",
            "Epoch 4 Loss 1.1728\n",
            "Time taken for 1 epoch 413.1242368221283 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.0115\n",
            "Epoch 5 Batch 100 Loss 1.0362\n",
            "Epoch 5 Loss 1.0003\n",
            "Time taken for 1 epoch 441.91834902763367 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.7807\n",
            "Epoch 6 Batch 100 Loss 0.8846\n",
            "Epoch 6 Loss 0.8322\n",
            "Time taken for 1 epoch 408.433123588562 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.7400\n",
            "Epoch 7 Batch 100 Loss 0.6545\n",
            "Epoch 7 Loss 0.6811\n",
            "Time taken for 1 epoch 409.8346116542816 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.4465\n",
            "Epoch 8 Batch 100 Loss 0.6049\n",
            "Epoch 8 Loss 0.5540\n",
            "Time taken for 1 epoch 409.4323625564575 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4257\n",
            "Epoch 9 Batch 100 Loss 0.5113\n",
            "Epoch 9 Loss 0.4485\n",
            "Time taken for 1 epoch 441.91973328590393 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.2946\n",
            "Epoch 10 Batch 100 Loss 0.3818\n",
            "Epoch 10 Loss 0.3577\n",
            "Time taken for 1 epoch 441.9209563732147 sec\n",
            "\n"
          ]
        }
      ]
    }
  ]
}